{
    "native_identifier": "lm-eval",
    "repo": "EleutherAI/lm-evaluation-harness",
    "registry": "py_pi",
    "tag_formats": [
        "v{major}.{minor}.{patch}"
    ],
    "sentinel_timestamp": "2020-01-01T00:00:00Z",
    "include": [
        "**/*.md",
        "**/*.py"
    ],
    "collection_name_prefix": "lm-eval",
    "version_sample_relative_size": 0.5,
    "version_sample_max_size": 5
}