{
	"native_identifier": "flash-linear-attention",
	"repo": "fla-org/flash-linear-attention",
	"registry": "pypi",
	"tag_formats": [
		"v{major}.{minor}.{patch}"
	],
	"sentinel_timestamp": "2024-01-01T00:00:00+0000",
	"include": [
		"**/*.md",
		"**/*.py"
	],
	"collection_name_prefix": "flash-linear-attention"
}
